{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../resources/TA_Logo.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "<h1 style=\"text-align: center;\">Data Science mit Python Projekt - AirBnB Berlin</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wofür ist dieses Dokument gedacht?\n",
    "Herzlich willkommen in dem Projekt-Leitfaden für dein TechAcademy *Data Science mit Python* Projekt! \n",
    "\n",
    "Diese Kurzbeschreibung des Projektes soll dir erste Anhaltspunkte dafür geben, wie du zu einem Ergebnis kommst. Dieses Dokument ist jedoch bewusst keine Schritt-für-Schritt Anleitung, wie du das Projekt durchführen sollst. Uns ist es wichtig, dass du dich in deinem Team selbst mit der Aufgabenstellung beschäftigst und eigene Wege findest, wie du zu einem Ergebnis kommst.  \n",
    "\n",
    "Da es aber besonders am Anfang nicht ganz offensichtlich sein kann, welche Schritte du durchlaufen sollst, geben wir dir mit diesem Dokument eine kleine Hilfestellung. Es wird sehr oft vorkommen, dass du nicht weiter weißt. Das ist ganz normal und gehört zu dem Lernprozess dazu. Du findest in unserem Handbuch Links zu sehr nützlichen Websites, wo deine Frage vermutlich schon einmal beantwortet wurde. Falls auch googlen dich nicht weiter bringt, stehen dir natürlich die Mentoren per Slack und bei unseren Coding Meetups persönlich zur Verfügung.\n",
    "\n",
    "Am Schluss dieses Dokumentes findest du eine Übersicht aller Aufgaben in diesem Projekt.\n",
    "Sehe diese Auflistung als Orientierungshilfe, welche Aufgaben noch zu erledigen sind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bevor es los geht\n",
    "## Um was geht das Projekt?\n",
    "\n",
    "Die Sharing Economy ist in aller Munde: Uber verändert das Taxi-Geschäft grundlegend, in der ganzen Stadt stehen seit neuestem Scooter herum und im Urlaub bucht man sich ein Airbnb und übernachtet in einer fremden Wohnung.\n",
    "Nachdem wir uns im letzten Semester ausführlich mit einem Leihfahrrad-Datensatz beschäftigt haben, schauen wir uns in diesem Semester das Geschäftsmodell Airbnb an.\n",
    "Genauer gesagt analysieren wir einen Teil eines sehr ausführlichen Datensatzes aller Airbnb Angebote in Berlin.\n",
    "Diese Daten wurden im November 2019 \"gescraped\", also von der Airbnb Homepage ausgelesen.\n",
    "Darin findet ihr allerhand nützliche und unnütze Informationen zu den Angeboten.\n",
    "\n",
    "Schon gespannt, das ganze selbst auszuprobieren? Analog zu einem typischen Data Science Workflow haben wir die Aufgaben in zwei Teile aufgeteilt.\n",
    "Als erstes lernst du in einer sogenannten Exploratory Data Analysis (EDA) den Datensatz genauer an und lernst die Variablen und deren Ausprägungen mit Grafiken kennen.\n",
    "Für Anfänger ist der Pflichtteil danach abgeschlossen - doch es lohnt sich, auch den Fortgeschrittenen Teil auszuprobieren.\n",
    "In diesem stellst du ein Modell auf, welches die Airbnb-Preise in Berlin möglichst akkurat vorhersagen kann.\n",
    "Ein Gefühl für dies bekommst du mit einem einfachen linearen Regressionsmodell, was du nach Belieben erweitern kannst.\n",
    "Doch alles der Reihe nach... Was genau ist EDA und was kann ich damit erreichen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Was ist das Ziel?\n",
    "**Explorative Datenanalyse – Lerne den Datensatz kennen**  \n",
    "\n",
    "Als ersten Schritt werden wir den Datansatz *deskriptiv* kennen lernen. Das heißt, wir nähern uns dem Ziel, indem wir die Daten *beschreiben*.\n",
    "Bei Data Science Projekten ist es sehr wichtig, sich zuallererst mit dem Datansatz vertraut zu machen.\n",
    "Welche Variablen sind in dem Datensatz enthalten und wie stehen sie im Verhältnis zueinander? Diese Fragen kann man sich sehr gut mit Grafiken beantworten.  \n",
    "Wir stellen dir dafür eine Reihe von strukturierten Aufgaben, die du nacheinander bearbeiten wirst. Anfänger, die bisher noch keine oder sehr wenige Statistik-Kenntnisse haben, können nach diesen Aufgaben aufhören - denn damit sind für Anfänger die Mindestvoraussetzungen erfüllt.\n",
    "Jedoch wird es gerade danach spannend.\n",
    "Versuche dich also auf jeden Fall trotzdem daran, wenn du noch etwas dazu lernen willst.\n",
    "\n",
    "Für diesen Abschnitt ist es sinnvoll, die ersten DataCamp Kurse in deinem Curriculum absolviert zu haben. Insbesondere folgende Kurse helfen dir weiter bei der Explorativen Datenanalyse:\n",
    "\n",
    "[Intro to Python for Data Science](https://www.datacamp.com/courses/introduction-to-data-science-in-python)\n",
    "\n",
    "[Intermediate Python for Data Science](https://www.datacamp.com/courses/intermediate-python-for-data-science)\n",
    "\n",
    "[Python For Data Science Toolbox (Part 1)](https://www.datacamp.com/courses/python-data-science-toolbox-part-1)\n",
    "\n",
    "[Importing Data in Python (Part 1)](https://www.datacamp.com/courses/importing-data-in-python-part-1)\n",
    "\n",
    "[Pandas Foundation](https://www.datacamp.com/courses/pandas-foundations)\n",
    "\n",
    "[Introduction to Matplotlib](https://www.datacamp.com/courses/introduction-to-matplotlib)\n",
    "\n",
    "[Exploratory Data Analysis with Python](https://www.datacamp.com/courses/exploratory-data-analysis-in-python)\n",
    "\n",
    "\n",
    "**Preisvorhersage – Wende statistische Methoden an**  \n",
    "\n",
    "Dieser Teil ist vornehmlich für etwas fortgeschrittenere Teilnehmer vorgesehen.\n",
    "Wenn du jedoch als Anfänger gut durch den ersten Abschnitt gekommen bist, empfehlen wir dir ausdrücklich, auch diesen Teil zu bearbeiten.\n",
    "Statistische Modelle sind ein enorm wichtiger Teil des Themenbereiches Data Science.  \n",
    "Nachdem wir den Datensatz kennen gelernt haben, können wir in diesem Schritt ein Modell entwickeln, mit dem wir die Airbnb Preise für einzelne Apartments zu unterschiedlichen Zeiten vorhersagen können. \n",
    "Cool, oder?\n",
    "Dein Ziel in diesem Abschnitt ist es, ein möglichst akkurates Modell dafür aufzustellen.\n",
    "Am Schluss schickst du uns deine Vorhersagen für einen kleinen Teil des Datensatzes, bei dem du den Preis noch nicht weißt.\n",
    "Wir vergleichen diese Vorhersagen dann mit den tatsächlichen Preisen und berechnen damit, wie akkurat dein Modell Preise vorhersagt.\n",
    "Das beste Modell gewinnt!\n",
    "\n",
    "Für diesen Abschnitt empfehlen wir dir folgende DataCamp Kurse. Beachte jedoch, dass es noch viele weitere Kurse gibt, die dir eine fortgeschrittenere Lösungsmöglichkeit beibringen.\n",
    "\n",
    "[Introduction to Linear Modeling in Python](https://www.datacamp.com/courses/introduction-to-linear-modeling-in-python)\n",
    "\n",
    "[Linear Classifiers in Python](https://www.datacamp.com/courses/linear-classifiers-in-python)\n",
    "\n",
    "[Introduction to Time Series Analysis in Pyhton](https://www.datacamp.com/courses/introduction-to-time-series-analysis-in-python)\n",
    "\n",
    "[Supervised Learning with Scikit Learn](https://www.datacamp.com/courses/supervised-learning-with-scikit-learn)\n",
    "\n",
    "[Unsupervised Learning in Python](https://www.datacamp.com/courses/unsupervised-learning-in-python)\n",
    "\n",
    "\n",
    "Alles klar? Dann lasse uns gleich starten, nachdem du jetzt einen Überblick über die Aufgaben hast!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorative Datenanalyse – Lerne den Datensatz kennen\n",
    "\n",
    "Im JupyterHub-Dateisystem und in dieser Datei findest du alles, was zur Bearbeitung der folgenden Aufgaben gebraucht wird!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Visualisieren der verfügbaren Apartments (on calendar dataset):\n",
    "\n",
    "1.1 Wandle die boolschen Werte t/f zu 1/0 um\n",
    "\n",
    "1.2 Aggregiere die Daten nach dem Datum\n",
    "\n",
    "1.3 Plotte die Anzahl der verfügbaren Apartments über die Zeit\n",
    "   \n",
    "   In diesem Abschnitt wendest du die grundlegensten Operationen an: Importieren, Bereinigen, Transformieren und am Schluss eine erste einfache Visualisierung des Datensatzes.\n",
    "   Zuerst muss der Datensatz aus deiner Ordnerstruktur in den Workspace geladen werden.\n",
    "   Importiere den `calendar` Datensatz in deinen Workspace und benenne das Objekt danach.\n",
    "\n",
    "   ```python\n",
    "   import pandas as pd\n",
    "   calendar = pd.read_csv(\"calendar.csv\")\n",
    "   ```\n",
    "\n",
    "   Verschaffe dir nun einen Überblick über den Datensatz.\n",
    "   Wie ist dieser aufgebaut und welche Variablen sind darin enthalten?\n",
    "   Was fällt dir dabei auf?\n",
    "   Dafür kannst du zum Beispiel folgende Funktionen nutzen:\n",
    "   ```python\n",
    "   calendar.head()\n",
    "   calendar.info()\n",
    "   calendar.describe()\n",
    "   ```\n",
    "\n",
    "   Bevor du dir überlegst, welche statistischen Methoden für die Vorhersage geeignet sein könnten, ist es immer nützlich sich die Zusammenhänge zwischen den Variablen visuell darzustellen.\n",
    "   Wie bereits oben angesprochen nennt man diesen Prozess Exploratory Data Analysis (EDA).\n",
    "\n",
    "   Bevor wir damit starten können, müssen wir den Datensatz zuerst ein wenig bearbeiten, damit die Funktionen diesen verarbeiten können.\n",
    "   Das klingt einfacher als gedacht – sehr oft sind die Daten in einem unbrauchbaren Format.\n",
    "   In unserem Fall ist zum Beispiel die Preis-Variable `price` als string-Variable gespeichert.\n",
    "   Damit Python diese verarbeiten kann, müssen wir ein Zeichen aus den Beobachtungen entfernen und die Variable in ein Zahlenformat bringen.\n",
    "   Dafür kannst du die Funktion `str.replace()` in Kombination mit `astype(float)` verwenden.\n",
    "\n",
    "   Damit der nächste Schritt leichter fällt, müssen wir noch die logische Variable `available` von einem Faktor zu einem `boolean` Datentyp konvertieren.\n",
    "   Nutze dafür die `apply()` Funktion für `pandas` und ersetze jeweils \"f\" und \"t\" mit den dazugehörigen logischen Werten `FALSE` oder `0` bzw. `TRUE` oder `1`.\n",
    "\n",
    "   Unser Ziel ist es nun, die Anzahl der verfügbaren Airbnb Apartments über das nächste Jahr in einem einfachen Lineplot darzustellen.\n",
    "   Jedoch ist unser Datensatz dafür noch nicht im richtigen Format - aktuell hat jedes Apartment einen Eintrag für jeden der kommenden 365 Tage und jeweils eine Variable, die uns anzeigt, ob das Apartment an diesem Tag verfügbar ist.\n",
    "   Unser transformierter Datensatz soll jedoch diese Infomationen zusammenfassen und nur einen einzigen Eintrag für jeden Tag im nächsten Jahr sowie die aggregierte Anzahl an verfügbaren Airbnbs in Berlin enthalten.\n",
    "   Nutze die `pandas` Funktionen `groupby()` und `sum()` dafür und speichere den daraus resultierenden Datensatz in einem neuen data frame ab, den du z.B. `avail_by_date` nennen kannst.\n",
    "   Nutze für diese Aufgabe gerne das `pandas` Cheat Sheet, auf welchem die Transformationen visuell dargestellt werden.\n",
    "\n",
    "   Jetzt haben wir den Datensatz in ein brauchbares Format gebracht und können die Ergebnisse visualisieren.\n",
    "   Bevor du dich an das Coden machst, überlege dir, was du von diesem Plot erwartest und wie er aussehen könnte.\n",
    "   Vergleiche diese Erwartungen dann mit dem tatsächlichen Plot und versuche die markanten Stellen mit deiner Intuition zu erklären.\n",
    "   Plotte dafür einen einfachen Lineplot, welcher die Anzahl der verfügbaren Apartments über die nächsten 365 Tage zeichnet.\n",
    "   Du kannst dafür `pandas` mit der Funktion `plot()` oder gleich die umfangreiche und sehr flexibel einsetzbare Grafiklibrary `matplotlib` verwenden.\n",
    "\n",
    "   Starte einfach und verfeinere dann deinen Plot.\n",
    "   So in etwa kann dein erstes Ergebnis ausschauen:\n",
    "\n",
    "![Availability](../resources/availability_plot_1.png)\n",
    "   \n",
    "   Überlege dir nun, was der Verlauf des Graphen bedeutet: Warum sind so viele regelmäßige Muster in der Verfügbarkeit?\n",
    "   Und warum gibt es immer wieder deutliche und abrupte Verringerungen der Verfügbarkeit?\n",
    "   Unten siehst du einen Beispielplot, wie man mit `matplotlib` einen einfachen Plot verfeinern kann und somit die Aufmerksamkeit der Betrachter auf bestimmte Muster lenken kann.\n",
    "   Halte dich jedoch nicht zu lange mit kleinen Feinheiten und Spielerein auf -- falls du am Schluss noch Zeit hast, kannst du dich noch einmal damit befassen.\n",
    "\n",
    "![Availability](../resources/availability_plot.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Visualisieren des listings Datensatz\n",
    "\n",
    "2.1 Bereinige und transformiere die Spalten `price` und `cleaning_fee` zu float-Werten\n",
    "\n",
    "2.2 Bestimme Mittelwert und Standardabweichung des Preises für Apartments nach Stadtteil\n",
    "\n",
    "2.3 Visualisiere die Preisverteilung des teuersten und günstigsten Stadtteils\n",
    "\n",
    "2.4 Visualisiere ob die `cleaning_fee` benutzt wird um die Preise versteckt zu erhöhen\n",
    "\n",
    "   Nachdem wir uns im ersten Schritt die Verfügbarkeit über die Zeit hinweg mithilfe des `calendar`-Datensatzes angeschaut haben, möchten wir nun etwas mehr über die Preisstrukturen der zur Verfügung stehenden Apartments herausfinden.\n",
    "   Dazu benötigen wir den `listings`-Datensatz, welchen wir wie gewohnt mit der pandas `read_csv()`-Methode laden können.\n",
    "   Wenn wir uns den Datensatz anschauen, beispielsweise mit der `head()`-Methode, so fällt auf, dass die Spalte\n",
    "   `price` und die Spalte `cleaning_fee` ein $-Zeichen enthalten. Dies ist für uns zwar wichtig, damit wir wissen, um welche Währungen es sich handelt, allerdings kann Python damit nichts anfangen und weiß nicht, wie der String in eine Zahl umgewandelt werden soll. \n",
    "\n",
    "   Daher muss für jede Spalte im Datensatz das Dollarzeichen gelöscht werden. Dies geht am besten mit der `replace()`-Methode. Hinzu kommt, dass in manchen Spalten ein Komma als Tausender-Trennzeichen verwendet wird. Diese Kommas in der `price`-Spalte können auf die gleiche Weise entfernt werden. Anschließend können die Spalten dann als Zahlen gedeutet werden und mit der `DataFrame.astype(float)`-Methode umgewandelt werden. Da du die gleiche Vorgehensweise für die Spalten `price` und `cleaning_fee` benutzt, bietet sich hier ein `for-loop` an.\n",
    "\n",
    "   Da wir jetzt den Datensatz gesäubert haben, können wir uns die Preisstruktur der verschiedenen Stadtteile genauer anschauen. Zunächst möchten wir wissen wie hoch der Durchschnittspreis und die zugehörige Standardabweichung für jeden Stadteil ist. Erstelle dazu eine Liste mit den Namen der verschiedenen Stadtteile und filtere den Datensatz jeweils nach einem der Stadteile. Nun kannst du den Durchschnittspreis und die Standardabweichung der verschiedenen Stadtteile bestimmen und dir ausgeben lassen, auch hier bietet sich wieder ein for-loop an.\n",
    "   Implementiere diese Schleife in einer selbst geschriebenen Funktion `clean_price()`, damit du dir besonders beim Vorhersageteil viele Zeilen Code sparst.\n",
    "\n",
    "   Nun möchten wir die Verteilung der Preise im durchschnittlich teuersten und im günstigsten Stadteil gegenüber stellen. Überlege dir dafür, welche Art von Diagramm du im Kurs kennengelernt hast und hier am meisten Sinn ergibt. Hast du das Diagramm erstellt, so musst du vermutlich einen Teil der Ausreißer mit extrem hohen Preisen herausfiltern, um einen aussagekräftigen Plot zu erhalten. Das Filtern kannst du aber ganz einfach beim plot-Befehl übergeben. Schaue dazu einfach online in der Dokumentation zur entsprechenden Methode nach.\n",
    "\n",
    "   Bei Airbnb können die verfügbaren Apartments nach Preis sortiert werden und dem Kunden in der entsprechenden Reihenfolge angezeigt werden. Eine Methode, um in dieser Rangliste weiter oben zu landen, ist es, einen günstigen Preis anzugeben und dafür eine höhere Reinigungsgebühr (Cleaning Fee) zu verlangen. Um dies weiter zu untersuchen, erstelle eine zusätzliche Spalte im Dataframe mit dem Namen `price_and_clean`. Untersuche nun, wie sich die Preisverteilung in den beiden zuvor untersuchten Stadteilen verändert. Stelle dazu beispielsweise den Preis sowie Preis+Reinigungsgebühr eines Stadteils in einem Diagramm gegenüber. Was kannst du hier beobachten?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Merging des `listings` und `review` Datensatzes\n",
    "\n",
    "3.1 Aggregiere die Reviews anhand der `ID`\n",
    "\n",
    "3.2 Merge `listings` und den aggregierten Reviews Datensatz\n",
    "\n",
    "3.3 Filtere Apartments und plotte die Anzahl dieser in einem Barplot nach Stadtteil\n",
    "   \n",
    "   Im vorherigen Teil hast du den `listings` Datensatz genauer kennen gelernt und visualisiert.\n",
    "   Eine wichtige Information ist jedoch nicht in diesem Datensatz enthalten: Wie beliebt sind die einzelnen Apartments?\n",
    "   Als Messgröße dafür verwenden wir die Anzahl der Bewertungen auf Airbnb.\n",
    "   Diese Variable könnte später für die Preisvorhersage sehr wichtig werden.\n",
    "   Zum Glück haben wir einen weiteren Datensatz `reviews`, indem zu jeder einzelnen Bewertung die Wohnungs-ID sowie das Datum gespeichert hat.\n",
    "   Unser Ziel ist es jetzt, für jedes einzelne Apartment die Anzahl der Bewertungen zu zählen und diese in einem Datensatz abuzuspeichern.\n",
    "   Da wir auch im `listings` Datensatz die ID finden, können wir anhand dieser Variable die zwei Datensätze zusammenführen.\n",
    "\n",
    "   Lese zuerst den neuen `reviews` Datensatz in deinen Workspace ein und schaue ihn dir mit den bekannten Funktionen genauer an.\n",
    "   Zähle nun die Anzahl der Bewertungen je Apartment.\n",
    "\n",
    "   Damit du die Datensätze mergen kannst, musst du die neu generierten Variablen in dem neuen Datensatz noch umbenennen.\n",
    "   Nenne die Wohnungs-ID analog zu dem `listings` Datensatz `id`, sowie die Anzahl der Bewertungen `n_reviews`.\n",
    "\n",
    "<img src=\"../resources/reviews_agg.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "\n",
    "   Wenn dein Datensatz so aussieht, kannst du ihn mit `listings` zusammenführen.\n",
    "   ```python\n",
    "   listings_reviews = pd.merge(dataset1, dataset2, left_on= ...)\n",
    "   ```\n",
    "\n",
    "   Schaue dir den neuen Datensatz an.\n",
    "   Ist die neue Variable `n_reviews` im richtigen Datentyp?\n",
    "\n",
    "   Wir wollen uns jetzt einen kleineren Teil des Datensatzes genauer anschauen: Was haben die beliebtesten Apartments gemainsam?\n",
    "   Als Indikator für die Beliebtheit eines Angebotes verwenden wir die vorher generierte Anzahl an Bewertungen `n_reviews`.\n",
    "\n",
    "   Extrahiere die 200 am meisten rezensierten Apartments.\n",
    "   Eine Herangehensweise dafür ist es, den Datensatz erst in absteigender Reihenfolge nach `n_reviews` zu sortieren und dann die ersten 200 Einträge in einen neuen Datensatz zu extrahieren.\n",
    "\n",
    "   Verwende nun wieder `matplotlib`, um zu visualisieren, in welchen Stadtteilen die 200 am häufigsten rezensierten Apartments liegen.\n",
    "   Ein Barplot bietet sich dafür an.\n",
    "   Versuche gerne auch andere Arten von Plots, mit denen sich diese Fragestellung am besten beantworten lassen kann.\n",
    "\n",
    "<img src=\"../resources/neigh_bar.png\" alt=\"Drawing\" style=\"width: 850px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Visualisiere die Apartments auf einer Karte\n",
    "\n",
    "4.1 Zeiche einen Punkt für jedes zur Verfügung stehende Apartment auf eine Karte\n",
    "\n",
    "4.2 Färbe die Punkte unterschiedlich, je nachdem in welchem Stadteil sie sind\n",
    "\n",
    "4.3 Erstelle eine 2d-Density Plot der Apartments auf einer Karte\n",
    "   \n",
    "   Wer die Internetseite von Airbnb kennt, der hat bestimmt auch die Funktion gesehen, die Apartments auf einer Karte anzeigen zu lassen. Das gleiche können wir auch! Nur, dass unsere Daten uns noch mehr Möglichkeiten geben anzuzeigen, was uns wirklich interessiert!\n",
    "\n",
    "   Wie kommen wir praktisch zu unserer Karte? Jupyter Notebooks machen es uns glücklicherweise leicht, interaktive Karten einzubinden. Die Library, die dazu notwendig ist, heißt [ipyleaflet](https://ipyleaflet.readthedocs.io/en/latest/). Eine einfache Karte von Berlin ist ganz, ganz simpel aufzurufen, indem man ein Kartenobjekt erstellt, dem man einen Mittelpunkt und einen Zoom mitgibt und dieses Objekt dann aufruft:\n",
    "   ```python\n",
    "   from ipyleaflet import Map, Marker\n",
    "\n",
    "   center = [52.5, 13.4]\n",
    "   m = Map(center=center, zoom=11)\n",
    "   m\n",
    "   ```\n",
    "   Jetzt können wir anfangen, Objekte auf der Karte zu platzieren. Damit die Karte nicht unübersichtlich wird, sollten nicht zu viele Apartments angezeigt werden. Praktisch ist dafür, dass wir in der letzten Aufgabe bereits eine Vorauswahl getroffen haben, die wir jetzt weiter benutzen können.\n",
    "\n",
    "   Plotte die 200 meistbewerteten Listings (aus Aufgabe 3) auf der Karte! (Wenn du Aufgabe 3 - noch - nicht gelöst hast, wähle einfach 200 Listings nach anderen Kriterien oder zufällig aus, um die Aufgabe zu lösen.)\n",
    "\n",
    "   In unseren Daten gibt es über die GPS-Koordinaten hinaus noch viele Informationen zu jedem Listing. Plotte die Listings diesmal in unterschiedlichen Farben. Nutze als Unterscheidungsmerkmal hierfür zunächst die Stadtteile (auch um leicht zu sehen, ob die Zuordnung funktioniert). Unter diesem Absatz findest du ein Beispiel, wie die Karte aussehen könnte. Nachdem das geklappt hat, verwende als Unterscheidungsmerkmal die Art des Listings (Apartment, Zimmer, ..).\n",
    "   \n",
    "<img src=\"../resources/airbnb_map_neighborhoods.jpg\" alt=\"Drawing\" style=\"width: 850px;\"/>\n",
    "   \n",
    "   Für einige Analysen ist es leichter, Schlüsse zu ziehen, wenn man nicht einfach nur Punkte auf einer Karte sieht, sondern Verteilungen. Um zum Beispiel zu erkennen, wo sich viele Apartments auf wenig Raum befinden, ist es nützlich anhand von Farbintensität auf der Karte, die Apartmentdichte darzustellen anstatt sie durch Punktansammlungen einzuschätzen. Erstelle einen solchen Dichteplot auf der Karte! Man kann zusätzlich auch wieder - wie oben - einen Schritt weiter gehen und weitere Informationen in den Dichteplot einfließen lassen. Erstelle einen Dichteplot für die Preise der Listings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preisvorhersage mit statistischen Verfahren (Fortgeschrittene und ambitionierte Anfänger)\n",
    "\n",
    "### 1. Visualisiere die Korrelationen der Features mit einer Heatmap\n",
    "\n",
    "### 2. Regression\n",
    "\n",
    "2.1 Einfaches Regressionsmodel mit einer erklärenden Variable\n",
    "\n",
    "2.2 Regressionsmodel mit zwei oder mehr Features\n",
    "\n",
    "### 3. Testen der Modelle\n",
    "\n",
    "3.1 Benutze den Testdatensatz um Preise für die Apartments vorherzusagen\n",
    "\n",
    "3.2 Vergleiche deine Prognosen mit den tatsächlichen Preisen mit Hilfe des RMSE\n",
    "\n",
    "3.3 Implementiere einen fortgeschrittenen Algorithmus und sende uns dein bestes Ergebnis zu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preisvorhersage – Wende statistische Methoden an\n",
    "\n",
    "Im vorherigen Teil hast du ein Gefühl für den Datensatz bekommen. Du weißt jetzt, welche Variablen enthalten sind und kennst ein paar charakteristische Eigenschaften des Datensatzes. Noch haben wir den Datensatz aber nur visualisiert. In diesem Abschnitt gehen wir einen Schritt weiter und wenden statistische Methoden an, um den Preis von einzelnen Airbnb Apartments möglichst genau vorherzusagen.\n",
    "\n",
    "Um dein Modell am Schluss vergleichen zu können, verwenden wir eine einheitliche Metrik, nach der wir die Preisvorhersagen auf Genauigkeit überprüfen können.\n",
    "In unserem Fall ist dies der Root Mean Squared Error ($RMSE$), also die Wurzel der durchschnittlich quadrierten Differenz zwischen dem vorhergesagten ($\\hat{y}_i$) und tatsächlichen Wert ($y_i$):\n",
    "\n",
    "\n",
    "$RMSE = \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}{(\\hat{y}_i-y_i)^2}}$\n",
    "\n",
    "\n",
    "Je näher der $RMSE$ an 0 ist, desto besser sagt dein Modell die Preise vorher.\n",
    "Dein Ziel ist es im Folgenden also den $RMSE$ deiner verschiedenen Modelle durch kontinuierliche Verbesserungen möglichst weit zu reduzieren.\n",
    "\n",
    "Wir nutzen für den folgenden Teil drei verschiedene Datensätze, welche du im Unterordner *Full Data Set* findest.\n",
    "Diese basieren auf einem deutlich umfangreicheren Datensatz, der insgesamt 96 Variablen für jedes Apartment enthält.\n",
    "Wir haben bereits den Test/Train/Validation split der Daten vorgenommen, damit jede Gruppe mit der gleichen Aufteilung arbeitet.\n",
    "Hier eine kurze Beschreibung, wofür du die Datensätze benötigst:\n",
    "\n",
    "* **train.csv** (60 \\%): Diesen Trainings-Datensatz verwendest du, um dein Modell zu trainieren. Das Modell lernt also die Zusammenhänge zwischen den Variablen dadurch kennen.\n",
    "* **test.csv** (30 \\%): Mit diesem Test-Datensatz kannst du testen, wie gut dein Modell den Preis mit Hilfe von bisher nicht gesehenen Daten vorhersagt. Dabei erkennst du zum Beispiel under-/overfitting.\n",
    "* **val.csv** (10 \\%): In diesem Validation-Datensatz haben wir die Variable `price` entfernt. Du wendest am Schluss dein bestes Modell darauf an und schickst uns deine Vorhersagen für `price`. Wir vergleichen diese dann mit den tatsächlichen (nur uns bekannten) Werten mit Hilfe des $RMSE$ und küren nach Projektabgabe das beste Modell über alle Gruppen hinweg.\n",
    "\n",
    "Beachte, dass in diesen drei Datensätzen wieder einige Bereinigungen notwendig sind.\n",
    "So sind zum Beispiel alle Preis-Variablen mit einem \\$-Zeichen versehen.\n",
    "Wir müssen diese entfernen, damit Python die Variablen als numerisch interpretieren kann und wir diese für die folgenden Modelle verwenden können. Behalte immer im Hinterkopf, dass du alle Transformationen auf alle drei Datensätze anwenden musst, da du sonst dein trainiertes Modell nicht auf den Test- sowie Validierungsdatensatz anwenden kannst."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Untersuche die Korrelation zwischen den Variablen näher (train)\n",
    "\n",
    "Lade zuerst den `train.csv` Datensatz aus dem Ordner *Full Data Set* in deinen Workspace.\n",
    "Schaue dir jetzt die Variablennamen und die ersten Einträge an um zu entscheiden, welche Daten für die Vorhersage des Preises nützlich sein können.\n",
    "Wähle diese (beschränke dich zuerst auf nicht mehr als 20 Variablen) plus `price` aus und speichere diese in einem neuen data.frame.\n",
    "\n",
    "Wie stehen einzelne Variablen miteinander in Verbindung?\n",
    "Sprich inwiefern korrelieren die Variablen des Datensatzes miteinander?\n",
    "Das herauszufinden ist enorm wichtig für die Entscheidung, welches Modell du später anwenden kannst.  \n",
    "Ein guter Anfang ist es, eine Korrelationsmatrix zu erstellen.\n",
    "Ein Teil dafür ist die Funktion `corr()` aus dem `pandas` package.\n",
    "Selektiere alle numerische Variablen in deinem Datensatzes und erstelle eine Korrelationsmatrix.\n",
    "\n",
    "Einen sehr praktischen Plot zur Visualisierung von Zusammenhängen zwischen vielen Variablen liefert das Package `seaborn` mit der Funktion `pairplot()`.\n",
    "Wähle die vier Variablen (und `price`) aus, die deiner Meinung nach am meisten den Preis beeinflussen und erstelle einen pair-Plot.\n",
    "Beachte hierbei, dass der Plot schnell unlesbar wird und lange zum Erstellen braucht, sobald du deutlich mehr als fünf Variablen plottest.\n",
    "\n",
    "<img src=\"../resources/pair_plot.png\" alt=\"Drawing\" style=\"width: 850px;\"/>\n",
    "\n",
    "Welche deiner untersuchten Variablen korreliert am meisten mit dem Preis und welche scheinen eher unabhängig vom Preis zu sein?\n",
    "Du hast jetzt einen ersten Eindruck, welche Variablen für dein Modell wichtig werden könnnten.\n",
    "Kommen wir also zu deinem ersten Preis-Vorhersage-Modell!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Erste Vorhersagen mit einfachen Regressionsmodellen (train)\n",
    "\n",
    "Jetzt kannst du dich mit deinen Statistik-Kenntnissen austoben:\n",
    "Du benötigst jetzt ein Verfahren, wie du den Preis eines Airbnb Apartments an einem bestimmten Tag vorhersagen kannst.  \n",
    "Eine erste sehr einfache Herangehensweise wäre den Durchschnitt der Nachfrage als erste Vorhersage zu verwenden. Ziemlich sicher ist das jedoch nicht die beste Vorhersage.\n",
    "Deine vorhergesagter Preis wäre in diesem Fall über alle Tage gleich und würde alle Faktoren, die den Preis beeinflussen, außer Acht lassen.\n",
    "\n",
    "Schon einmal was von einer linearen Regression gehört? Das wäre ein deutlich besserer Ansatz.\n",
    "Jetzt kannst du deine Statistik-Skills ausspielen.\n",
    "Stelle zuerst ein Modell mit der abhängigen Variable `price` auf.\n",
    "In der vorherigen Aufgabe hast du unterschiedliche Variablen untersucht.\n",
    "Suche dir jetzt diejenige Variable mit der höchsten Korrelation zum Preis aus und verwende diese als einzige unabhängige Variable.\n",
    "\n",
    "Dein erstes Regressionsmodell könnte zum Beispiel so aussehen:\n",
    "\n",
    "$price = \\beta_0 + \\beta_1 bedrooms + \\epsilon$\n",
    "\n",
    "Hat deine unabhängige Variable einen statistisch signifikanten Einfluss auf den Apartment-Preis?\n",
    "Vermutlich ja, denn wir haben als einzige die am höchsten zum Preis korrelierte Variable ausgewählt.\n",
    "Wenn wir jedoch bei diesem sehr vereinfachten Modell bleiben, begehen wir einen typischen Fehler:\n",
    "Den sogenannten Omitted Variable Bias (OVB).\n",
    "Grob vereinfacht gesprochen vernachlässigen wir (im Statistik-Jargon: kontrollieren nicht für) Variablen, die einen signifikanten Einfluss auf die abhängige Variable haben.\n",
    "Man könnte vermuten, dass andere Einflussfaktoren auch eine große Rolle bei der Preisbildung haben.\n",
    "Wenn wir diese also nicht mit aufnehmen, ist die Schätzung des Effektes von $bedrooms$ verzerrt und damit schlecht zu gebrauchen.\n",
    "In diesem Fall ist das vorerst kein großes Problem für uns, da wir nicht an kausalen Effekten, sondern aussließlich an einer möglichst guten Vorhersage interessiert sind.\n",
    "Deinem Statistik-Prof würden bei so einem Modell ziemlich sicher die Haare zu Berge stehen.\n",
    "Nichtsdestotrotz wird dieses Modell mit nur einer einzigen erklärenden Variable den Preis nicht unbedingt gut vorhersagen.  \n",
    "\n",
    "Eine Lösungsmöglichkeit ist, die vernachlässigten Variablen einfach mit in das Modell aufzunehmen –- wie praktisch, dass diese auch schon in dem Datensatz enthalten sind. Stellen wir also ein etwas umfangreicheres Modell auf, das die noch eine weitere Variable mit aufnimmt:\n",
    "\n",
    "$price = \\beta_0 + \\beta_1 bedrooms + \\beta_2 cleaning\\_fee + \\epsilon$ \n",
    "\n",
    "Vergleiche nun die Ergebnisse der beiden Modelle.\n",
    "Erklärt das umfangreichere Modell einen höheren Anteil der Varianz im Preis?\n",
    "Sprich welches Modell weist dem höheren Wert für das Bestimmtheitsmaß $R^2$ aus?\n",
    "\n",
    "<img src=\"../resources/reg_summary.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Von Training zu Testen – Treffe Vorhersagen\n",
    "\n",
    "Jetzt hast du dein erstes Modell mit dem Trainings-Datensatz *trainiert*.\n",
    "Doch wie gut geht das Modell mit Daten um, die es noch nicht gesehen hat?\n",
    "Das ist ein sehr wichtiger Test um die Qualität deines Modells zu bewerten.  \n",
    "\n",
    "Hat dein Modell nur die vorhandenen Muster im Trainings-Datensatz \"auswendig\" gelernt?\n",
    "Dann wären die Zusammenhänge aus dem Trainings-Datensatz nicht übertragbar auf den Test-Datensatz.\n",
    "Beim sogenannten Overfitting hat das Modell zu nah am Trainings-Datensatz gelernt und liefert deshalb schlechte Vorhersagen bei unbekannten Daten –- zum Beispiel in deinem Test- und Validierungs-Datensatz.  \n",
    "Auf der andern Seite gibt es auch das Problem Underfitting: Dein Modell hat die tatsächlichen Zusammenhänge der Daten nicht ausreichend gelernt und sagt deshalb in dem Test-Datensatz schlecht voraus.\n",
    "Es gilt also, die goldene Mitte zwischen den beiden Problemen zu finden.  \n",
    "\n",
    "Jetzt wird die Unterscheidung zwischen Trainings- und Testdatensatz wichtig. Zur Erinnerung: wir nutzen `train`, um ein Modell zu **trainieren** und `test`, um die Qualität unseres Modells letztendlich zu **testen**.\n",
    "\n",
    "Lade nun zusätzlich zu dem Datensatz `train`, den du bereits vorher verwendet hast, den Datensatz `test`.\n",
    "Um nun dein Modell an bisher ungesehenen Daten zu testen, kannst du das Modell auf den `test` Datensatz anwenden.\n",
    "Nutze dafür die Funktion predict:\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "predicted_price = reg.predict(X_test)\n",
    "```\n",
    "\n",
    "Damit hast du einen Vektor mit allen Preisvorhersagen für den `test` Datensatz erstellt.\n",
    "Diesen kannst du jetzt mit den tatsächlichen Werten für `price` aus `test` vergleichen.\n",
    "Um eine einheitliche Vergleichsmetrik zu verwenden, nutze bitte folgende Funktion zur Messung deiner Vorhersagegenauigkeit.\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# Function that returns Root Mean Squared Error while ignoring NAs\n",
    "rmse = mean_absolute_error(y_test, predicted_price)\n",
    "```\n",
    "\n",
    "Vergleiche nun beide Regressionsmodelle.\n",
    "Hat das umfangreichere Modell bessere Vorhersagegenauigkeit, also einen niedrigeren $RMSE$?\n",
    "Jetzt hast du einen Benchmark für deine fortgeschritteneren Modelle, den es im nächsten Teil zu schlagen gilt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Wende fortgeschrittene Machine Learning-Algorithmen an\n",
    "\n",
    "Nachdem du jetzt eine erste Vorhersage mit Hilfe eines einfachen Regressionsmodells erstellt und getestet hast, kannst du dich jetzt an fortgeschrittenere Methoden herantasten.\n",
    "Das Ziel ist immer noch, einen möglichst niedrigen $RMSE$ beim Anwenden des Modells auf dem `test` Datensatz zu erhalten.\n",
    "Suche dir jetzt mindestens einen anderen Algorithmus heraus und überprüfe letztendlich, ob du dadurch eine akkuratere Vorhersage (ausgedrückt durch niedrigeren $RMSE$) erhältst.\n",
    "Inspirationen dazu findest du bei den fortgeschrittenen DataCamp-Kursen, welche am Anfang des Leitfadens aufgelistet sind.\n",
    "Dir sind dabei keine Grenzen gesetzt -- du kannst die Regression durch bestimmte Verfahren verfeinern (z.B. LASSO) oder gleich ein Random Forest Modell oder ein Neuronales Netzwerk aufstellen.\n",
    "Es ist meistens eine gute Idee, sich kurz die Funktionsweise der jeweiligen Algorithmen in Erinnerung zu rufen und zu überlegen, ob diese Methodik in diesem Fall bei einer kontinuierlichen Vorhersagevariable Sinn macht.\n",
    "\n",
    "An dieser Stelle ist ein Hinweis angebracht: Unser Datensatz hat über viele Variablen teilweise einen substantiellen Teil an fehlenden Beobachtungen (`NA`).\n",
    "Einige Machine Learning Algorithmen verlangen einen vollständigen Datensatz ohne Missing Values, während andere mit einer kleineren Anzahl gut zurecht kommen.\n",
    "Überprüfe also zuerst, ob du die Missing Values durch ein bestimmtes Verfahren imputieren (\"imputieren\" bedeutet, dass du deine `NA` durch einen Wert ersetzt, der auf Basis der restlichen Werte oder den anderen Variablen berechnet wird. So kannst du zum Beispiel den fehlenden Wert durch eine Regression auf die restlichen Variablen vorhersagen) kannst.\n",
    "Welche Methode dafür am besten geeignet ist, hängt stark von deinem Vorhersage-Algorithmus ab.\n",
    "\n",
    "Zudem kannst du einen spürbaren Zugewinn an Vorhersagekraft erhalten, indem du bestehende Variablen modifizierst oder neue Variablen aus dem Datensatz generierst (\"feature engineering\").\n",
    "Zum Beispiel könnten wir uns vorstellen, dass die Distanz eines Apartments zum Stadtzentrum einen deutlichen Einfluss auf den Preis hat.\n",
    "Diese Variable ist jedoch nicht in unserem Datensatz enthalen.\n",
    "Du kannst jedoch eine einfache Funktion schreiben, die mit Hilfe der zwei Koordinaten-Variablen die Distanz zum Zentrum Berlins berechnet und diese als neue Variable an den Datensatz anhängt.\n",
    "\n",
    "Vergleiche immer den $RMSE$ deiner fortgeschrittenen Modelle unterienander, sowie im Vegleich zu dem Benckmark Regressionsmodell. \n",
    "\n",
    "Du hast dein bestes Modell gefunden? Dann wende wie oben die Funktion `predict()` mit deinem Gewinnermodell an -- dieses mal jedoch auf den Validierungs-Datensatz `val`.\n",
    "\n",
    "Schicke in Anhang deiner Projektabgabe einen .csv Datensatz in folgendem Format mit den beiden einzigen Variablen `id` und `predicted_price` mit.\n",
    "\n",
    "<img src=\"../resources/submission_format.png\" alt=\"Drawing\" style=\"width: 250px;\"/>\n",
    "\n",
    "Dies erreichst du, indem du die beiden Vektoren `id` und `predicted_price` aneinanderfügst und als .csv Datei abspeicherst."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damit hast du alle Aufgaben bearbeitet!\n",
    "Wir hoffen du hattest Spaß beim Programmieren und hast einige spannende Methoden in Python gelernt.\n",
    "Vergesse nicht, dein PDF Dokument und die eben generierte .csv Datei vor der Deadline an unsere Projektabgabe-Email-Adresse zu schicken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # Noch Fragen?\n",
    "\n",
    "   Du kommst nicht weiter? Willst dein Modell noch weiter verbessern, weißt aber nicht genau wie? Oder dir fällt gerade nicht ein, wie man etwas bestimmtes im Code umsetzt? Schaue dir noch einmal unser Handbuch an. Dort findest du hilfreiche Hinweise, wie du in diesem Fall weiter verfahren und wo du nach einer Lösung für deine Fragestellung suchen kannst."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../resources/vars.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgaben-Checkliste für das Airbnb Data Science Projekt\n",
    "\n",
    "## Exploratory Data Analysis (Anfänger + Fortgeschrittene)\n",
    "\n",
    "### 1. Visualisieren der verfügbaren Apartments (on calendar dataset):\n",
    "\n",
    "1.1 Wandle die boolschen Werte t/f zu 1/0 um\n",
    "\n",
    "1.2 Aggregiere die Daten nach dem Datum\n",
    "\n",
    "1.3 Plotte die Anzahl der verfügbaren Apartments über die Zeit\n",
    "\n",
    "### 2. Visualisieren des listings Datensatz\n",
    "\n",
    "2.1 Bereinige und transformiere die Spalten `price` und `cleaning_fee` zu float-Werten\n",
    "\n",
    "2.2 Bestimme Mittelwert und Standardabweichung des Preises für Apartments nach Stadtteil\n",
    "\n",
    "2.3 Visualisiere die Preisverteilung des teuersten und günstigsten Stadtteils\n",
    "\n",
    "2.4 Visualisiere ob die `cleaning_fee` benutzt wird um die Preise versteckt zu erhöhen\n",
    "\n",
    "### 3. Merging des `listings` und `review` Datensatzes\n",
    "\n",
    "3.1 Aggregiere die Reviews anhand der `ID`\n",
    "\n",
    "3.2 Merge `listings` und den aggregierten Reviews Datensatz\n",
    "\n",
    "3.3 Filtere Apartments und plotte die Anzahl dieser in einem Barplot nach Stadtteil\n",
    "\n",
    "### 4. Visualisiere die Apartments auf einer Karte\n",
    "\n",
    "4.1 Zeiche einen Punkt für jedes zur Verfügung stehende Apartment auf eine Karte\n",
    "\n",
    "4.2 Färbe die Punkte unterschiedlich, je nachdem in welchem Stadteil sie sind\n",
    "\n",
    "4.3 Erstelle eine 2d-Density Plot der Apartments auf einer Karte\n",
    "\n",
    "## Preisvorhersage mit statistischen Verfahren (Fortgeschrittene und ambitionierte Anfänger)\n",
    "\n",
    "### 1. Visualisiere die Korrelationen der Features mit einer Heatmap\n",
    "\n",
    "### 2. Regression\n",
    "\n",
    "2.1 Einfaches Regressionsmodel mit einer erklärenden Variable\n",
    "\n",
    "2.2 Regressionsmodel mit zwei oder mehr Features\n",
    "\n",
    "### 3. Testen der Modelle\n",
    "\n",
    "3.1 Benutze den Testdatensatz um Preise für die Apartments vorherzusagen\n",
    "\n",
    "3.2 Vergleiche deine Prognosen mit den tatsächlichen Preisen mit Hilfe des RMSE\n",
    "\n",
    "3.3 Implementiere einen fortgeschrittenen Algorithmus und sende uns dein bestes Ergebnis zu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
